
Found 988 files belonging to 5 classes.
2024-06-29 22:26:50.976461: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[INFO] Getting file paths and shuffling
[INFO] Configuring training and testing data
[INFO] Creating ImageFolder's for training and validation datasets
Found 790 files belonging to 5 classes.
Found 99 files belonging to 5 classes.
/var/folders/n_/4p37f261177fmjpv4kt7x33m0000gn/T/ipykernel_438/2517264663.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.
  ("MobileNetV2", MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3)))
[INFO] Training model: VGG16
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Found 988 files belonging to 5 classes.
2024-06-29 22:30:11.748269: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[INFO] Getting file paths and shuffling
[INFO] Configuring training and testing data
[INFO] Creating ImageFolder's for training and validation datasets
Found 790 files belonging to 5 classes.
Found 99 files belonging to 5 classes.
[INFO] Training model: VGG16
/var/folders/n_/4p37f261177fmjpv4kt7x33m0000gn/T/ipykernel_438/2517264663.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.
  ("MobileNetV2", MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3)))
[INFO] Training model: VGG16
[INFO] Training model: VGG16
Epoch 1/10


[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m0s[22m 165ms/step - categorical_accuracy: 0.3840 - loss: 3.6889 - top_k_categorical_accuracy: 0.7840
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m7s[22m 204ms/step - categorical_accuracy: 0.3888 - loss: 3.6517 - top_k_categorical_accuracy: 0.7864 - val_categorical_accuracy: 0.7980 - val_loss: 0.5755 - val_top_k_categorical_accuracy: 1.0000
Epoch 2/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 170ms/step - categorical_accuracy: 0.8004 - loss: 0.7723 - top_k_categorical_accuracy: 0.9648 - val_categorical_accuracy: 0.8990 - val_loss: 0.3549 - val_top_k_categorical_accuracy: 1.0000
Epoch 3/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 171ms/step - categorical_accuracy: 0.8844 - loss: 0.3776 - top_k_categorical_accuracy: 0.9952 - val_categorical_accuracy: 0.9091 - val_loss: 0.2662 - val_top_k_categorical_accuracy: 1.0000
Epoch 4/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 170ms/step - categorical_accuracy: 0.9000 - loss: 0.3972 - top_k_categorical_accuracy: 0.9915 - val_categorical_accuracy: 0.9192 - val_loss: 0.2537 - val_top_k_categorical_accuracy: 0.9798
Epoch 5/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 170ms/step - categorical_accuracy: 0.9281 - loss: 0.2650 - top_k_categorical_accuracy: 0.9986 - val_categorical_accuracy: 0.9192 - val_loss: 0.1944 - val_top_k_categorical_accuracy: 0.9899
Epoch 6/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 170ms/step - categorical_accuracy: 0.9286 - loss: 0.2027 - top_k_categorical_accuracy: 0.9997 - val_categorical_accuracy: 0.9394 - val_loss: 0.2355 - val_top_k_categorical_accuracy: 0.9899
Epoch 7/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 171ms/step - categorical_accuracy: 0.9553 - loss: 0.1384 - top_k_categorical_accuracy: 0.9984 - val_categorical_accuracy: 0.9293 - val_loss: 0.2315 - val_top_k_categorical_accuracy: 0.9899
Epoch 8/10


[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 171ms/step - categorical_accuracy: 0.9684 - loss: 0.0846 - top_k_categorical_accuracy: 0.9979 - val_categorical_accuracy: 0.9394 - val_loss: 0.2304 - val_top_k_categorical_accuracy: 0.9899
Epoch 9/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 171ms/step - categorical_accuracy: 0.9605 - loss: 0.1078 - top_k_categorical_accuracy: 1.0000 - val_categorical_accuracy: 0.9192 - val_loss: 0.2465 - val_top_k_categorical_accuracy: 0.9899
Epoch 10/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m4s[22m 172ms/step - categorical_accuracy: 0.9544 - loss: 0.1392 - top_k_categorical_accuracy: 1.0000 - val_categorical_accuracy: 0.9495 - val_loss: 0.2475 - val_top_k_categorical_accuracy: 0.9798
[INFO] Training model: ResNet50
Epoch 1/10


[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m19s[22m 580ms/step - categorical_accuracy: 0.3657 - loss: 2.2670 - top_k_categorical_accuracy: 0.7113 - val_categorical_accuracy: 0.8283 - val_loss: 0.5597 - val_top_k_categorical_accuracy: 1.0000
Epoch 2/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 139ms/step - categorical_accuracy: 0.7519 - loss: 0.6573 - top_k_categorical_accuracy: 0.9752 - val_categorical_accuracy: 0.9192 - val_loss: 0.3159 - val_top_k_categorical_accuracy: 0.9798
Epoch 3/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 131ms/step - categorical_accuracy: 0.8648 - loss: 0.3287 - top_k_categorical_accuracy: 0.9922 - val_categorical_accuracy: 0.9192 - val_loss: 0.2638 - val_top_k_categorical_accuracy: 1.0000
Epoch 4/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 124ms/step - categorical_accuracy: 0.9186 - loss: 0.2082 - top_k_categorical_accuracy: 0.9973 - val_categorical_accuracy: 0.9091 - val_loss: 0.2190 - val_top_k_categorical_accuracy: 1.0000
Epoch 5/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 122ms/step - categorical_accuracy: 0.9460 - loss: 0.1377 - top_k_categorical_accuracy: 0.9995 - val_categorical_accuracy: 0.9495 - val_loss: 0.1884 - val_top_k_categorical_accuracy: 1.0000
Epoch 6/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 122ms/step - categorical_accuracy: 0.9570 - loss: 0.1122 - top_k_categorical_accuracy: 0.9996 - val_categorical_accuracy: 0.9293 - val_loss: 0.2516 - val_top_k_categorical_accuracy: 1.0000
Epoch 7/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 122ms/step - categorical_accuracy: 0.9702 - loss: 0.0846 - top_k_categorical_accuracy: 0.9954 - val_categorical_accuracy: 0.9192 - val_loss: 0.2665 - val_top_k_categorical_accuracy: 1.0000
Epoch 8/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 121ms/step - categorical_accuracy: 0.9714 - loss: 0.0844 - top_k_categorical_accuracy: 1.0000 - val_categorical_accuracy: 0.9394 - val_loss: 0.2360 - val_top_k_categorical_accuracy: 1.0000
Epoch 9/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 122ms/step - categorical_accuracy: 0.9697 - loss: 0.0921 - top_k_categorical_accuracy: 1.0000 - val_categorical_accuracy: 0.9293 - val_loss: 0.2801 - val_top_k_categorical_accuracy: 1.0000
Epoch 10/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 120ms/step - categorical_accuracy: 0.9750 - loss: 0.0642 - top_k_categorical_accuracy: 0.9997 - val_categorical_accuracy: 0.9596 - val_loss: 0.2262 - val_top_k_categorical_accuracy: 1.0000
[INFO] Training model: InceptionV3
Epoch 1/10


[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m24s[22m 707ms/step - categorical_accuracy: 0.2195 - loss: 56.6605 - top_k_categorical_accuracy: 0.7396 - val_categorical_accuracy: 0.2020 - val_loss: 33.1944 - val_top_k_categorical_accuracy: 0.7677
Epoch 2/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 107ms/step - categorical_accuracy: 0.2690 - loss: 25.2185 - top_k_categorical_accuracy: 0.6864 - val_categorical_accuracy: 0.4343 - val_loss: 2.3730 - val_top_k_categorical_accuracy: 0.8586
Epoch 3/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 88ms/step - categorical_accuracy: 0.3190 - loss: 6.5102 - top_k_categorical_accuracy: 0.7506 - val_categorical_accuracy: 0.4545 - val_loss: 1.4728 - val_top_k_categorical_accuracy: 0.8687
Epoch 4/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 90ms/step - categorical_accuracy: 0.4001 - loss: 2.5277 - top_k_categorical_accuracy: 0.8148 - val_categorical_accuracy: 0.3939 - val_loss: 1.3332 - val_top_k_categorical_accuracy: 0.8283
Epoch 5/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 89ms/step - categorical_accuracy: 0.3635 - loss: 1.5511 - top_k_categorical_accuracy: 0.7604 - val_categorical_accuracy: 0.4242 - val_loss: 1.3911 - val_top_k_categorical_accuracy: 0.8586
Epoch 6/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m3s[22m 106ms/step - categorical_accuracy: 0.3631 - loss: 1.4478 - top_k_categorical_accuracy: 0.8033 - val_categorical_accuracy: 0.4040 - val_loss: 1.3692 - val_top_k_categorical_accuracy: 0.8788
Epoch 7/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 92ms/step - categorical_accuracy: 0.3167 - loss: 1.4736 - top_k_categorical_accuracy: 0.7139 - val_categorical_accuracy: 0.3232 - val_loss: 1.4782 - val_top_k_categorical_accuracy: 0.7273
Epoch 8/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 93ms/step - categorical_accuracy: 0.3054 - loss: 1.5278 - top_k_categorical_accuracy: 0.7011 - val_categorical_accuracy: 0.2929 - val_loss: 1.5631 - val_top_k_categorical_accuracy: 0.6768
Epoch 9/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 86ms/step - categorical_accuracy: 0.2934 - loss: 1.4889 - top_k_categorical_accuracy: 0.6812 - val_categorical_accuracy: 0.4545 - val_loss: 1.3257 - val_top_k_categorical_accuracy: 0.8889
Epoch 10/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 86ms/step - categorical_accuracy: 0.3089 - loss: 1.4547 - top_k_categorical_accuracy: 0.7215 - val_categorical_accuracy: 0.5152 - val_loss: 1.3326 - val_top_k_categorical_accuracy: 0.8586
[INFO] Training model: MobileNetV2
Epoch 1/10


[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m14s[22m 351ms/step - categorical_accuracy: 0.3263 - loss: 1.8863 - top_k_categorical_accuracy: 0.7094 - val_categorical_accuracy: 0.6364 - val_loss: 0.9179 - val_top_k_categorical_accuracy: 0.9596
Epoch 2/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 77ms/step - categorical_accuracy: 0.5733 - loss: 1.0891 - top_k_categorical_accuracy: 0.8906 - val_categorical_accuracy: 0.6061 - val_loss: 0.8503 - val_top_k_categorical_accuracy: 0.9394
Epoch 3/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 66ms/step - categorical_accuracy: 0.7331 - loss: 0.6884 - top_k_categorical_accuracy: 0.9488 - val_categorical_accuracy: 0.6970 - val_loss: 0.7067 - val_top_k_categorical_accuracy: 0.9596
Epoch 4/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 68ms/step - categorical_accuracy: 0.7515 - loss: 0.6443 - top_k_categorical_accuracy: 0.9750 - val_categorical_accuracy: 0.7172 - val_loss: 0.6629 - val_top_k_categorical_accuracy: 0.9495
Epoch 5/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 65ms/step - categorical_accuracy: 0.8321 - loss: 0.4600 - top_k_categorical_accuracy: 0.9895 - val_categorical_accuracy: 0.8283 - val_loss: 0.5109 - val_top_k_categorical_accuracy: 0.9596
Epoch 6/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 64ms/step - categorical_accuracy: 0.8583 - loss: 0.4032 - top_k_categorical_accuracy: 0.9829 - val_categorical_accuracy: 0.7576 - val_loss: 0.6587 - val_top_k_categorical_accuracy: 0.9798
Epoch 7/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 71ms/step - categorical_accuracy: 0.8524 - loss: 0.4034 - top_k_categorical_accuracy: 0.9825 - val_categorical_accuracy: 0.7980 - val_loss: 0.5168 - val_top_k_categorical_accuracy: 0.9697
Epoch 8/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 70ms/step - categorical_accuracy: 0.8900 - loss: 0.3158 - top_k_categorical_accuracy: 0.9903 - val_categorical_accuracy: 0.7879 - val_loss: 0.5298 - val_top_k_categorical_accuracy: 0.9596
Epoch 9/10
[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 66ms/step - categorical_accuracy: 0.8960 - loss: 0.2786 - top_k_categorical_accuracy: 0.9944 - val_categorical_accuracy: 0.8182 - val_loss: 0.4995 - val_top_k_categorical_accuracy: 0.9899
Epoch 10/10

[1m25/25[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m2s[22m 61ms/step - categorical_accuracy: 0.8920 - loss: 0.2722 - top_k_categorical_accuracy: 0.9936 - val_categorical_accuracy: 0.8283 - val_loss: 0.4274 - val_top_k_categorical_accuracy: 0.9798